{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Clone repos from github","metadata":{}},{"cell_type":"code","source":"%%capture\n!git clone https://github.com/hukenovs/hagrid.git\n# or mirror link:\n%cd hagrid\n# Install requirements\n%pip install -r requirements.txt --user\n%cd ..\n# !wget https://raw.githubusercontent.com/shitkov/signature_detector/main/dataset.zip\n!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -qr requirements.txt\n# !unzip /content/dataset.zip -d /content/yolov5/\n%cd ..","metadata":{"id":"mzl9mnLrvLfp","execution":{"iopub.status.busy":"2022-10-12T08:42:40.804281Z","iopub.execute_input":"2022-10-12T08:42:40.804870Z","iopub.status.idle":"2022-10-12T08:43:07.766498Z","shell.execute_reply.started":"2022-10-12T08:42:40.804720Z","shell.execute_reply":"2022-10-12T08:43:07.765197Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## YOLOv5 habr","metadata":{"id":"ykt4DSstyIJA"}},{"cell_type":"code","source":"%%capture\n# !wget https://raw.githubusercontent.com/shitkov/signature_detector/main/dataset.zip\n!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -qr requirements.txt\n# !unzip /content/dataset.zip -d /content/yolov5/\n%cd ..","metadata":{"id":"VE-8E7yTyHMb","execution":{"iopub.status.busy":"2022-10-12T08:43:07.768844Z","iopub.execute_input":"2022-10-12T08:43:07.769147Z","iopub.status.idle":"2022-10-12T08:43:18.281297Z","shell.execute_reply.started":"2022-10-12T08:43:07.769117Z","shell.execute_reply":"2022-10-12T08:43:18.280021Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing annotation files to YOLOv5 format","metadata":{}},{"cell_type":"code","source":"import json\nimport os\n\nYOLO_ANN_TRAIN_JSON_PATH = '/kaggle/input/hagrid-call-test/ann_train_val/ann_train_val/call.json'\nYOLO_ANN_TEST_JSON_PATH  = '/kaggle/input/hagrid-call-test/ann_test/ann_test/call.json'\nYOLO_ANN_TRAIN_TXTS_PATH = '/kaggle/working/labels_train'\nYOLO_ANN_TEST_TXTS_PATH  = '/kaggle/working/labels_test'\nHAGRID_PHOTO_TRAIN_PATH  = '/kaggle/input/hagrid-call-test/train_val_call'\nHAGRID_PHOTO_TEST_PATH   = '/kaggle/input/hagrid-call-test/test/call'\n\nYOLO_ANN_FAKES_JSON_PATH = '/kaggle/input/hagrid-call-test/ann_test/ann_test'\nYOLO_ANN_FAKES_TXTS_PATH = '/kaggle/working/labels_fakes'\nHAGRID_PHOTO_FAKES_PATH  = '/kaggle/input/hagrid-call-test/test'\n\n\ndef preprocess_json2txt(json_path:str, txt_path:str, photo_path:str) -> None:\n    dct={}\n    with open(json_path) as f:\n        d = json.load(f)\n        for key in d:\n            dct[key] = d[key]\n\n    if not(os.path.isdir(txt_path)):\n        os.mkdir(txt_path)\n\n    filenames = []\n    for (dirpath, dirnames, f) in os.walk(photo_path):\n        filenames.extend(f)\n        break\n\n    for filename in filenames:\n        name = filename.split('.')[0]\n        with open(os.path.join(txt_path, name+'.txt'), 'w') as f:\n            lines = []\n            for i in range(len(dct[name]['bboxes'])):\n                label = (1 if dct[name]['labels'][i]=='call' else 0)\n                bbox = [dct[name]['bboxes'][i][0]+0.5*dct[name]['bboxes'][i][2],\n                        dct[name]['bboxes'][i][1]+0.5*dct[name]['bboxes'][i][3],\n                        dct[name]['bboxes'][i][2],\n                        dct[name]['bboxes'][i][3]]\n                lines.append(str(label) + ' ' + ' '.join(str(x) for x in bbox) + '\\n')\n            f.writelines(lines)\n            \npreprocess_json2txt(YOLO_ANN_TRAIN_JSON_PATH, YOLO_ANN_TRAIN_TXTS_PATH, HAGRID_PHOTO_TRAIN_PATH)\npreprocess_json2txt(YOLO_ANN_TEST_JSON_PATH,  YOLO_ANN_TEST_TXTS_PATH,  HAGRID_PHOTO_TEST_PATH )\n\nfakes_names=['dislike','fist','four','like','mute','ok','one','palm','peace','peace_inverted','rock',\\\n             'stop','stop_inverted','three','three2','two_up','two_up_inverted']\n\nfor name in fakes_names:\n    preprocess_json2txt(os.path.join(YOLO_ANN_FAKES_JSON_PATH, name+'.json'),\\\n                        YOLO_ANN_FAKES_TXTS_PATH,\\\n                        os.path.join(HAGRID_PHOTO_FAKES_PATH, name))","metadata":{"id":"BKOi6CJT_5wu","execution":{"iopub.status.busy":"2022-10-12T08:43:18.284191Z","iopub.execute_input":"2022-10-12T08:43:18.284955Z","iopub.status.idle":"2022-10-12T08:44:24.504827Z","shell.execute_reply.started":"2022-10-12T08:43:18.284898Z","shell.execute_reply":"2022-10-12T08:44:24.503757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"### OBSOLETE\ndef create_dataset(dataset_path:str, img_train_path:str, label_train_path:str, valid_size:float,\n                  random_state:int):\n    np.random.seed(random_state)\n    dirpath=''\n    images = []\n    for (dirpath_, dirpaths, filenames) in os.walk(img_train_path):\n        images.extend(filenames)\n        dirpath += dirpath_\n        break\n        \n    images.sort()\n    n = len(images)\n    train_indices = np.arange(n)\n    np.random.shuffle(train_indices)\n    train_indices = train_indices[:n]\n    mask = np.zeros(n, dtype=np.bool)\n    for i in train_indices:\n        mask[i]=1\n    \n    for i,image in enumerate(images):\n        name = image.split('.')[0]\n        dir_type = ('train' if i in mask[i]==1 else 'valid')\n        exec(f'!cp -s {os.path.join(img_train_path, image)}' + \\\n             f'{os.path.join(dataset_path, \"images\", dir_type, image)}')\n        txt = name+'.txt'\n        exec(f'!cp -s {os.path.join(label_train_path, txt)}' + \\\n             f'{os.path.join(dataset_path, \"labels\", dir_type, txt)}')\n        \n# create_dataset('/kaggle/temp/dataset', HAGRID_PHOTO_TRAIN_PATH, YOLO_ANN_TRAIN_TXTS_PATH, valid_size=0.05, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:24.507902Z","iopub.execute_input":"2022-10-12T08:44:24.508821Z","iopub.status.idle":"2022-10-12T08:44:24.517958Z","shell.execute_reply.started":"2022-10-12T08:44:24.508777Z","shell.execute_reply":"2022-10-12T08:44:24.516896Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/temp/dataset/images\n!mkdir -p /kaggle/temp/dataset/labels\n%cd ../temp\n!cp -r -s '/kaggle/input/hagrid-call-test/train_val_call' './dataset/images'\n!mv './dataset/images/train_val_call' './dataset/images/train'\n!cp -r -s '/kaggle/input/hagrid-call-test/test/call'      './dataset/images'\n!mv './dataset/images/call' './dataset/images/valid'\n!cp -r -s '/kaggle/working/labels_train' './dataset/labels'\n!mv './dataset/labels/labels_train' './dataset/labels/train'\n!cp -r -s '/kaggle/working/labels_test' './dataset/labels'\n!mv './dataset/labels/labels_test' './dataset/labels/valid'\n%cd ../working","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:24.519653Z","iopub.execute_input":"2022-10-12T08:44:24.520155Z","iopub.status.idle":"2022-10-12T08:44:50.233797Z","shell.execute_reply.started":"2022-10-12T08:44:24.520115Z","shell.execute_reply":"2022-10-12T08:44:50.232427Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/temp\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"from multiprocessing import Pool\n\ndef _scan_folder(dataset_path, dirs):\n    lists = {}\n    s1='images'\n    for s2 in dirs:\n        lists[s2] = []\n        cur_path = os.path.join(dataset_path, s1, s2)\n        for (dirpath, dirpaths, filenames) in os.walk(cur_path):\n                for i in range(len(filenames)):\n                    filenames[i] = filenames[i].split('.')[0]\n                lists[s2].extend(sorted(filenames))\n    return lists\n\ndef _trim_dataset_helper(dataset_path:str, s2:str, name:str):\n    os.remove(os.path.join(dataset_path, 'images', s2, name + '.jpg'))\n    os.remove(os.path.join(dataset_path, 'labels', s2, name + '.txt'))\n    \ndef trim_dataset(dataset_path:str, n_train:int, n_valid:int, batch_index=0):\n    dirs = [['images','labels'], ['train','valid']]\n    lists = _scan_folder(dataset_path, dirs[1]) \n    \n    for s2 in dirs[1]:\n        n = (n_train if s2=='train' else n_valid)\n        filenames = lists[s2].copy()\n        _start = (batch_index * n) % (len(filenames))\n        _end   = _start + n\n        filenames = ((filenames[:_start] + filenames[_end:]) if _end <= len(filenames) else \\\n                      filenames[_end%len(filenames):_start])\n            \n        with Pool(4) as p:\n            p.starmap(_trim_dataset_helper, [(dataset_path, s2, name) for name in filenames])\n                \n    lists = _scan_folder(dataset_path, dirs[1])\n    return lists","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:50.235950Z","iopub.execute_input":"2022-10-12T08:44:50.237082Z","iopub.status.idle":"2022-10-12T08:44:50.248718Z","shell.execute_reply.started":"2022-10-12T08:44:50.237036Z","shell.execute_reply":"2022-10-12T08:44:50.247785Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def _copy_fakes_helper(dataset_path:str, image_path:str, label_path:str, filename:str, dir_type:str):\n    filename = filename.split('.')[0]\n    os.popen(f\"cp -s {os.path.join(image_path, filename+'.jpg')} \" + \\\n             f\"{os.path.join(dataset_path, 'images', dir_type)}\")\n    os.popen(f\"cp -s {os.path.join(label_path, filename+'.txt')} \" + \\\n             f\"{os.path.join(dataset_path, 'labels', dir_type)}\") \n    \ndef copy_fakes(dataset_path:str, image_path:str, label_path:str, n_train:int,\n               n_valid:int, fakes_names:list, batch_index=0):\n    \n    n_train = n_train//len(fakes_names)\n    n_valid = n_valid//len(fakes_names)\n    \n    for name in fakes_names:\n        dir_path = os.path.join(image_path,name)\n        filenames = sorted(os.listdir(dir_path))\n        _start = (batch_index * (n_train + n_valid)) % (len(filenames))\n        _end   = _start + (n_train + n_valid)\n        filenames = (filenames[_start:_end] if _end <= len(filenames) else \\\n                     filenames[_start:] + filenames[:_end%len(filenames)])\n        \n        with Pool(4) as p:\n            p.starmap(_copy_fakes_helper, [(dataset_path, dir_path, label_path, filename, 'train')\\\n                                           for filename in filenames[:n_train]])\n        with Pool(4) as p:\n            p.starmap(_copy_fakes_helper, [(dataset_path, dir_path, label_path, filename, 'valid')\\\n                                           for filename in filenames[n_train:n_train+n_valid]])\n        \n    lists = _scan_folder(dataset_path, ['train','valid'])\n    return lists","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:50.250280Z","iopub.execute_input":"2022-10-12T08:44:50.250914Z","iopub.status.idle":"2022-10-12T08:44:51.541899Z","shell.execute_reply.started":"2022-10-12T08:44:50.250872Z","shell.execute_reply":"2022-10-12T08:44:51.540791Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# _scan_folder('/kaggle/temp/dataset', [['images','labels'], ['train','valid']])","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:51.543832Z","iopub.execute_input":"2022-10-12T08:44:51.544649Z","iopub.status.idle":"2022-10-12T08:44:51.557533Z","shell.execute_reply.started":"2022-10-12T08:44:51.544608Z","shell.execute_reply":"2022-10-12T08:44:51.556485Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Trimming dataset","metadata":{}},{"cell_type":"code","source":"N_TRAIN = 5000\nN_VALID = 500\nBATCH_INDEX=4\n\ndataset_files = trim_dataset('/kaggle/temp/dataset', N_TRAIN//2, N_VALID//2, BATCH_INDEX)\ndataset_files = copy_fakes('/kaggle/temp/dataset', HAGRID_PHOTO_FAKES_PATH, YOLO_ANN_FAKES_TXTS_PATH,\n                          N_TRAIN//2, N_VALID//2, fakes_names, BATCH_INDEX)\nprint(f\"Batch index: {BATCH_INDEX}\\n\" + \\\n      f\"Train dataset length: {len(dataset_files['train'])}\\n\" + \\\n      f\"Valid dataset length: {len(dataset_files['valid'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:44:51.559115Z","iopub.execute_input":"2022-10-12T08:44:51.559514Z","iopub.status.idle":"2022-10-12T08:45:48.039640Z","shell.execute_reply.started":"2022-10-12T08:44:51.559477Z","shell.execute_reply":"2022-10-12T08:45:48.038484Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Batch index: 3\nTrain dataset length: 4999\nValid dataset length: 488\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('./sig.yaml', 'w') as f:\n    f.write('train: /kaggle/temp/dataset/images/train/\\n' + \\\n            'val: /kaggle/temp/dataset/images/valid/\\n' + \\\n            '\\n' + \\\n            'nc: 2\\n' + \\\n            \"names: ['no_gesture','call']\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:45:48.043993Z","iopub.execute_input":"2022-10-12T08:45:48.044305Z","iopub.status.idle":"2022-10-12T08:45:48.054811Z","shell.execute_reply.started":"2022-10-12T08:45:48.044273Z","shell.execute_reply":"2022-10-12T08:45:48.053743Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!cat ./sig.yaml","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:45:48.056520Z","iopub.execute_input":"2022-10-12T08:45:48.057198Z","iopub.status.idle":"2022-10-12T08:45:49.013454Z","shell.execute_reply.started":"2022-10-12T08:45:48.057147Z","shell.execute_reply":"2022-10-12T08:45:49.012224Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"train: /kaggle/temp/dataset/images/train/\nval: /kaggle/temp/dataset/images/valid/\n\nnc: 2\nnames: ['no_gesture','call']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image, clear_output\nfrom gc import collect\ncollect()","metadata":{"id":"KFeBQo73VwWC","execution":{"iopub.status.busy":"2022-10-12T08:45:49.015241Z","iopub.execute_input":"2022-10-12T08:45:49.015984Z","iopub.status.idle":"2022-10-12T08:45:50.766674Z","shell.execute_reply.started":"2022-10-12T08:45:49.015940Z","shell.execute_reply":"2022-10-12T08:45:50.765697Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"## Download weights","metadata":{}},{"cell_type":"code","source":"!wget -O yolov5s.pt https://github.com/SpryGorgon/YOLOv5/raw/main/yolov5s_640_40.pt","metadata":{"execution":{"iopub.status.busy":"2022-10-12T08:45:50.768020Z","iopub.execute_input":"2022-10-12T08:45:50.768933Z","iopub.status.idle":"2022-10-12T08:45:54.424644Z","shell.execute_reply.started":"2022-10-12T08:45:50.768894Z","shell.execute_reply":"2022-10-12T08:45:54.423494Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"--2022-10-12 08:45:51--  https://github.com/SpryGorgon/YOLOv5/raw/main/yolov5s_1280_30.pt\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/SpryGorgon/YOLOv5/main/yolov5s_1280_30.pt [following]\n--2022-10-12 08:45:52--  https://raw.githubusercontent.com/SpryGorgon/YOLOv5/main/yolov5s_1280_30.pt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14624117 (14M) [application/octet-stream]\nSaving to: ‘yolov5s.pt’\n\nyolov5s.pt          100%[===================>]  13.95M  55.9MB/s    in 0.2s    \n\n2022-10-12 08:45:54 (55.9 MB/s) - ‘yolov5s.pt’ saved [14624117/14624117]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training YOLOv5","metadata":{}},{"cell_type":"code","source":"%cd yolov5\n!python train.py --img 640 --batch -1 --epochs 10 --data '../sig.yaml' --device 0 --cfg yolov5s.yaml --weights ../yolov5s.pt --cache disk\n%cd ..","metadata":{"id":"MT6Fw41HNamX","outputId":"b588a0be-2ded-4fe1-954c-9801e86d27ca","execution":{"iopub.status.busy":"2022-10-12T08:45:54.426617Z","iopub.execute_input":"2022-10-12T08:45:54.426958Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=../yolov5s.pt, cfg=yolov5s.yaml, data=../sig.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=disk, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v6.2-189-g2f1eb21 Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs in Weights & Biases\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 7.23MB/s]\nOverriding model.yaml nc=80 with nc=2\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nYOLOv5s summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n\nTransferred 348/349 items from ../yolov5s.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.90G total, 0.10G reserved, 0.05G allocated, 15.75G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     7025023       15.95         0.256         62.64         21.26        (1, 3, 640, 640)                    list\n     7025023       31.91         0.436         16.09         26.45        (2, 3, 640, 640)                    list\n     7025023       63.82         0.818         19.61          40.9        (4, 3, 640, 640)                    list\n     7025023       127.6         2.143         34.37         63.64        (8, 3, 640, 640)                    list\n     7025023       255.3         3.819         65.06         97.25       (16, 3, 640, 640)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 51 for CUDA:0 12.58G/15.90G (79%) ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00039843750000000003), 60 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/temp/dataset/labels/train' images and labels...4999 fou\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/temp/dataset/labels/train.cache\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (37.6GB disk): 100%|██████████| 4999/4999 [06:39<00:00, 12\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/temp/dataset/labels/valid' images and labels...488 found,\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/temp/dataset/labels/valid.cache\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.7GB disk): 100%|██████████| 488/488 [00:44<00:00, 10.85it\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.99 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to runs/train/exp/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/exp\u001b[0m\nStarting training for 10 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        0/9      11.1G    0.02509   0.009672   0.001508        106        640:  ","output_type":"stream"}]},{"cell_type":"code","source":"!cp './yolov5/runs/train/exp/weights/best.pt' -r '/kaggle/working/yolov5s_640_40.pt'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validating ","metadata":{}},{"cell_type":"code","source":"%cd yolov5\n!python val.py --weights './runs/train/exp/weights/best.pt' --data '../sig.yaml' --img 640 --device 0\n%cd ..","metadata":{"id":"NrWsa07POIVj","outputId":"26c7b0a6-1cfe-4283-edd8-d8d770153e28","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from PIL import Image\n# img = Image.open('yolov5/runs/val/exp/val_batch2_pred.jpg')\n# img.show()\n\n\n# model = torch.hub.load('yolov5', 'custom', path='yolov5n_640_30.pt', source='local')\n# imgs = ['/kaggle/temp/dataset/images/valid/' + x + '.jpg' for x in dataset_files['valid']]\n# results = model(['/kaggle/temp/dataset/images/valid/e9524db2-1590-4c77-a084-ac217907e56f.jpg'])\n# results.print()\n# results.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Detecting","metadata":{}},{"cell_type":"code","source":"%cd yolov5\n!python detect.py --weights './runs/train/exp/weights/best.pt' --imgsz 640 --device 0 --source /kaggle/temp/dataset/images/valid\n%cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving runs output to .tar","metadata":{}},{"cell_type":"code","source":"!tar -czf runs_output.zip './yolov5/runs'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Running detection on test","metadata":{}},{"cell_type":"code","source":"# %cd yolov5\n# !mkdir -p /kaggle/temp/runs\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/call\n# !mv runs/detect/exp /kaggle/temp/runs/call\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/dislike\n# !mv runs/detect/exp /kaggle/temp/runs/dislike\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/fist\n# !mv runs/detect/exp /kaggle/temp/runs/fist\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/four\n# !mv runs/detect/exp /kaggle/temp/runs/four\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/like\n# !mv runs/detect/exp /kaggle/temp/runs/like\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/mute\n# !mv runs/detect/exp /kaggle/temp/runs/mute\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/ok\n# !mv runs/detect/exp /kaggle/temp/runs/ok\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/one\n# !mv runs/detect/exp /kaggle/temp/runs/one\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/palm\n# !mv runs/detect/exp /kaggle/temp/runs/palm\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/peace\n# !mv runs/detect/exp /kaggle/temp/runs/peace\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/peace_inverted\n# !mv runs/detect/exp /kaggle/temp/runs/peace_inverted\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/rock\n# !mv runs/detect/exp /kaggle/temp/runs/rock\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/stop\n# !mv runs/detect/exp /kaggle/temp/runs/stop\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/stop_inverted\n# !mv runs/detect/exp /kaggle/temp/runs/stop_inverted\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/three\n# !mv runs/detect/exp /kaggle/temp/runs/three\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/three2\n# !mv runs/detect/exp /kaggle/temp/runs/three2\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/two_up\n# !mv runs/detect/exp /kaggle/temp/runs/two_up\n# !python detect.py --weights '../yolov5s.pt' --imgsz 640 --device 0 --source /kaggle/input/hagrid-call-test/test/two_up_inverted\n# !mv runs/detect/exp /kaggle/temp/runs/two_up_inverted\n# %cd ..\n# !tar -czf runs_output.zip '/kaggle/temp/runs'","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}